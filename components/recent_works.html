<!-- Publications -->
<section id="publications" class="py-12 px-4 sm:px-6 lg:px-8 max-w-7xl mx-auto">
    <h2 class="text-3xl font-bold mb-8 text-center text-primary">Recent Works</h2>
    <div class="space-y-6">

        <div class="glass-effect p-6 rounded-xl hover-scale">
            <h3 class="text-xl font-semibold mb-2">Beyond VLM-Based Rewards: Diffusion-Native Latent Reward Modeling</h3>
            <p class="text-black text-sm">Gongye Liu, Bo Yang, Yida Zhi, Zhizhou Zhong, Lei Ke, Didan Deng, Han Gao, Yongxiang Huang, Kaihao Zhang, Hongbo Fu, Wenhan Luo</p>
            <p class="text-black text-sm">arXiv:2602.11146.</p>
            [<a href="https://arxiv.org/abs/2602.11146" target="_blank">arXiv</a>]
            [<a href="https://github.com/HKUST-C4G/diffusion-rm/" target="_blank">Code</a>]
        </div>
        
        <div class="glass-effect p-6 rounded-xl hover-scale">
            <h3 class="text-xl font-semibold mb-2">Visual-Aware CoT: Achieving High-Fidelity Visual
                Consistency in Unified Models</h3>
            <p class="text-black text-sm">Zixuan Ye, Quande Liu, Cong Wei, Yuanxing Zhang, Xintao Wang,
                Pengfei Wan, Kun Gai, Wenhan Luo</p>
            <p class="text-black text-sm">arXiv:2512.19686.</p>
            [<a href="https://arxiv.org/abs/2512.19686" target="_blank">arXiv</a>]
            [<a href="https://zixuan-ye.github.io/VACoT/" target="_blank">Project Page</a>]
        </div>

        <div class="glass-effect p-6 rounded-xl hover-scale">
            <h3 class="text-xl font-semibold mb-2">AnyTalker: Scaling Multi-Person Talking Video Generation
                with Interactivity Refinement</h3>
            <p class="text-black text-sm">Zhizhou Zhong, Yicheng Ji, Zhe Kong, Yiying Liu, Jiarui Wang,
                Jiasun Feng, Lupeng Liu, Xiangyi Wang, Yanjia Li, Yuqing She, Ying Qin, Huan Li, Shuiyang
                Mao, Wei Liu, Wenhan Luo</p>
            <p class="text-black text-sm">arXiv:2511.23475.</p>
            [<a href="https://arxiv.org/abs/2511.23475" target="_blank">arXiv</a>]
            [<a href="https://hkust-c4g.github.io/AnyTalker-homepage/" target="_blank">Project Page</a>]
            [<a href="https://github.com/HKUST-C4G/AnyTalker" target="_blank">Code</a>]
            [<a href="https://huggingface.co/spaces/C4G-HKUST/AnyTalker" target="_blank">Gradio</a>]
            [<a href="https://huggingface.co/zzz66/AnyTalker-1.3B/tree/main" target="_blank">Hugging Face
                Model</a>]
            <img alt="GitHub stars" style="vertical-align:middle"
                src="https://img.shields.io/github/stars/HKUST-C4G/AnyTalker?style=social" />
        </div>

        <div class="glass-effect p-6 rounded-xl hover-scale">
            <h3 class="text-xl font-semibold mb-2">UNIC: Unified In-Context Video Editing</h3>
            <p class="text-black text-sm">Zixuan Ye, Xuanhua He, Quande Liu, Qiulin Wang, Xintao Wang,
                Pengfei Wan, Di Zhang, Kun Gai, Qifeng Chen, Wenhan Luo</p>
            <p class="text-black text-sm">International Conference on Learning Representations (ICLR), 2026.</p>
            [<a href="https://arxiv.org/abs/2506.04216" target="_blank">arXiv</a>]
            [<a href="https://zixuan-ye.github.io/UNIC/" target="_blank">Project Page</a>]
        </div>

        <div class="glass-effect p-6 rounded-xl hover-scale">
            <h3 class="text-xl font-semibold mb-2">Let Them Talk: Audio-Driven Multi-Person Conversational
                Video Generation</h3>
            <p class="text-black text-sm">Zhe Kong, Feng Gao, Yong Zhang, Zhuoliang Kang, Xiaoming Wei,
                Xunliang Cai, Guanying Chen, Wenhan Luo</p>
            <p class="text-black text-sm">Neural Information Processing Systems (NeurIPS), 2025.</p>
            [<a href="https://arxiv.org/abs/2505.22647" target="_blank">PDF</a>]
            [<a href="https://meigen-ai.github.io/multi-talk/" target="_blank">Project Page</a>]
            [<a href="https://github.com/MeiGen-AI/MultiTalk/" target="_blank">Code</a>]
            [<a href="https://huggingface.co/MeiGen-AI/MeiGen-MultiTalk" target="_blank">Hugging Face
                Model</a>]
            [<a href="https://huggingface.co/spaces/fffiloni/Meigen-MultiTalk" target="_blank">Gradio</a>]
            <img alt="GitHub stars" style="vertical-align:middle"
                src="https://img.shields.io/github/stars/MeiGen-AI/MultiTalk?style=social" />
        </div>

        <div class="glass-effect p-6 rounded-xl hover-scale">
            <h3 class="text-xl font-semibold mb-2">Foundation Cures Personalization: Improving Personalized
                Models' Prompt Consistency via Hidden Foundation Knowledge</h3>
            <p class="text-black text-sm">Yiyang Cai, Zhengkai Jiang, Yulong Liu, Chunyang Jiang, Wei Xue,
                Yike Guo, Wenhan Luo,</p>
            <p class="text-black text-sm">Neural Information Processing Systems (NeurIPS), 2025.</p>
            [<a href="https://arxiv.org/abs/2411.15277" target="_blank">PDF</a>]
            [<a href="https://freecure.github.io/" target="_blank">Project Page</a>]
            [<a href="https://github.com/YIYANGCAI/FreeCure" target="_blank">Code</a>]
            <img alt="GitHub stars" style="vertical-align:middle"
                src="https://img.shields.io/github/stars/YIYANGCAI/FreeCure?style=social">
        </div>



        <!-- <div class="glass-effect p-6 rounded-xl hover-scale">
            <h3 class="text-xl font-semibold mb-2">MaterialMVP: Illumination-Invariant Material Generation
                via Multi-view PBR Diffusion</h3>
            <p class="text-black text-sm">Zebin He, Mingxin Yang, Shuhui Yang, Yixuan Tang, Tao Wang,
                Kaihao Zhang, Guanying Chen, Yuhong Liu, Jie Jiang, Chunchao Guo, Wenhan Luo</p>
            <p class="text-black text-sm">Proc. of International Conference on Computer Vision (ICCV),
                Hawaii, USA, 2025. (<strong>
                    <font color="red">Highlight</font>
                </strong>)</p>
            [<a href="https://arxiv.org/abs/2503.10289" target="_blank">arXiv</a>]
            [<a href="https://zebinhe.github.io/MaterialMVP/" target="_blank">Project Page</a>]
            [<a href="https://github.com/ZebinHe/MaterialMVP" target="_blank">Code</a>]
            <img alt="GitHub stars" style="vertical-align:middle"
                src="https://img.shields.io/github/stars/ZebinHe/MaterialMVP?style=social" />
        </div>
        <div class="glass-effect p-6 rounded-xl hover-scale">
            <h3 class="text-xl font-semibold mb-2">MOERL: When Mixture-of-Experts Meet Reinforcement
                Learning for Adverse Weather Image Restoration</h3>
            <p class="text-black text-sm">Tao Wang, Peiwen Xia, Bo Li, Peng-Tao Jiang, Zhe Kong, Kaihao
                Zhang, Tong Lu, Wenhan Luo</p>
            <p class="text-black text-sm">Proc. of International Conference on Computer Vision (ICCV),
                Hawaii, USA, 2025.</p>

        </div>
        <div class="glass-effect p-6 rounded-xl hover-scale">
            <h3 class="text-xl font-semibold mb-2">DAM-VSR: Disentanglement of Appearance and Motion for
                Video Super-Resolution</h3>
            <p class="text-black text-sm">Zhe Kong, Le Li, Yong Zhang, Feng Gao, Shaoshu Yang, Tao Wang,
                Kaihao Zhang, Zhuoliang Kang, Xiaoming Wei, Guanying Chen, Wenhan Luo</p>
            <p class="text-black text-sm">ACM SIGGRAPH, 2025.</p>
            [<a href="" target="_blank">PDF</a>]
            [<a href="https://kongzhecn.github.io/projects/dam-vsr/" target="_blank">Project Page</a>]
            [<a href="https://github.com/kongzhecn/DAM-VSR" target="_blank">Code</a>]
            <img alt="GitHub stars" style="vertical-align:middle"
                src="https://img.shields.io/github/stars/kongzhecn/DAM-VSR?style=social" />
        </div>
        <div class="glass-effect p-6 rounded-xl hover-scale">
            <h3 class="text-xl font-semibold mb-2">StyleMaster: Stylize Your Video with Artistic Generation
                and Translation</h3>
            <p class="text-black text-sm">Zixuan Ye, Huijuan Huang, Xintao Wang, Pengfei Wan, Di Zhang,
                Wenhan Luo</p>
            <p class="text-black text-sm">Proc. of IEEE Conf. on Computer Vision and Pattern Recognition
                (CVPR), 2025.</p>
            [<a href="https://arxiv.org/pdf/2412.07744" target="_blank">arXiv</a>]
            [<a href="https://github.com/KwaiVGI/StyleMaster" target="_blank">Github</a>]
            [<a href="https://zixuan-ye.github.io/stylemaster/" target="_blank">Project Page</a>]
            <img alt="GitHub stars" style="vertical-align:middle"
                src="https://img.shields.io/github/stars/KwaiVGI/StyleMaster?style=social" />
        </div>

        <div class="glass-effect p-6 rounded-xl hover-scale">
            <h3 class="text-xl font-semibold mb-2">Towards Multiple Character Image Animation Through
                Enhancing Implicit Decoupling</h3>
            <p class="text-black text-sm">Jingyun Xue, Hongfa Wang, Qi Tian, Yue Ma, Andong Wang, Zhiyuan
                Zhao, Shaobo Min, Wenzhe Zhao, Kaihao Zhang, Heung-Yeung Shum, Wei Liu, Mengyang Liu, Wenhan
                Luo</p>
            <p class="text-black text-sm">International Conference on Learning Representations (ICLR),
                2025.</p>
            [<a href="https://openreview.net/forum?id=aqlzXgXwWa" target="_blank">PDF</a>]
            [<a href="https://multi-animation.github.io/" target="_blank">Project Page</a>]
            [<a href="https://cloud.tencent.com/product/vclm" target="_blank">API in Tencent Cloud</a>]
        </div> -->

    </div>
    <div class="text-center mt-8">
        <a href="assets/pages/publication.html" target="_blank"
            class="inline-flex items-center px-6 py-3 border border-primary text-primary rounded-full hover:bg-primary hover:text-white transition-colors duration-300">
            View Full Publications <i class="fas fa-book ml-2"></i>
        </a>
    </div>
</section>
